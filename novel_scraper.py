import os
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options

# --- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---
NOVEL_URL = "https://www.webnovel.com/book/beast-taming-the-more-the-better_29379860808949905"
OUTPUT_FOLDER = "novel_chapters"
# ÙŠÙ…ÙƒÙ† ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„ÙØµÙˆÙ„ Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ø³Ø­Ø¨Ù‡Ø§ (Ù„Ù„ØªØ¬Ø±Ø¨Ø© )
# Ø§Ø¶Ø¨Ø·Ù‡ Ø¹Ù„Ù‰ None Ù„Ø³Ø­Ø¨ ÙƒÙ„ Ø§Ù„ÙØµÙˆÙ„
CHAPTER_LIMIT = 5 

def setup_driver():
    """Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ØªØµÙØ­ Chrome Ù„Ù„Ø¹Ù…Ù„ ÙÙŠ Ø¨ÙŠØ¦Ø© Codespace."""
    chrome_options = Options()
    chrome_options.add_argument("--headless")  # ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…ØªØµÙØ­ ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ© Ø¨Ø¯ÙˆÙ† ÙˆØ§Ø¬Ù‡Ø© Ø±Ø³ÙˆÙ…ÙŠØ©
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    
    # Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø± WebDriver Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø«Ø¨ØªÙ‹Ø§ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­
    driver = webdriver.Chrome(options=chrome_options)
    return driver

def get_chapter_links(driver, url):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ÙØµÙˆÙ„ Ù…Ù† ØµÙØ­Ø© Ø§Ù„Ø±ÙˆØ§ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©."""
    print("â³ Ø¬Ø§Ø±ÙŠ Ø²ÙŠØ§Ø±Ø© ØµÙØ­Ø© Ø§Ù„Ø±ÙˆØ§ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙˆØ¬Ù…Ø¹ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ÙØµÙˆÙ„...")
    driver.get(url)
    time.sleep(5)  # Ø§Ù†ØªØ¸Ø± 5 Ø«ÙˆØ§Ù†Ù Ù„Ù„Ø³Ù…Ø§Ø­ Ù„Ù„ØµÙØ­Ø© Ø¨Ø§Ù„ØªØ­Ù…ÙŠÙ„

    # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙƒÙ„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªÙŠ ØªØ¤Ø¯ÙŠ Ø¥Ù„Ù‰ Ø§Ù„ÙØµÙˆÙ„
    # Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙˆÙ‚Ø¹ØŒ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¯Ø§Ø®Ù„ Ø¹Ù†Ø§ØµØ± <a> Ù…Ø¹ ÙØ¦Ø© 'j_chap-item'
    chapter_elements = driver.find_elements(By.CSS_SELECTOR, "a.j_chap-item")
    
    links = [elem.get_attribute('href') for elem in chapter_elements if elem.get_attribute('href')]
    
    if not links:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±ÙˆØ§Ø¨Ø· ÙØµÙˆÙ„. Ù‚Ø¯ ÙŠÙƒÙˆÙ† ØªØµÙ…ÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ù‚Ø¯ ØªØºÙŠØ±.")
        return []
        
    print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(links)} Ø±Ø§Ø¨Ø· ÙØµÙ„.")
    return links

def scrape_chapter(driver, url):
    """Ø³Ø­Ø¨ Ø¹Ù†ÙˆØ§Ù† ÙˆÙ†Øµ Ø§Ù„ÙØµÙ„ Ù…Ù† Ø±Ø§Ø¨Ø· Ù…Ø¹ÙŠÙ†."""
    print(f"   - Ø¬Ø§Ø±ÙŠ Ø³Ø­Ø¨ Ø§Ù„ÙØµÙ„ Ù…Ù†: {url}")
    driver.get(url)
    time.sleep(3) # Ø§Ù†ØªØ¸Ø± Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØµÙ„

    try:
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙØµÙ„
        title_element = driver.find_element(By.CSS_SELECTOR, "h2.j_chap-title")
        title = title_element.text.strip()
    except:
        title = "Untitled Chapter"

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Øµ Ø§Ù„ÙØµÙ„
    # Ø§Ù„Ù†Øµ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø®Ù„ Ø¹Ù†Ø§ØµØ± <p> Ø¯Ø§Ø®Ù„ Ø­Ø§ÙˆÙŠØ© Ø§Ù„ÙØµÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    paragraphs = driver.find_elements(By.CSS_SELECTOR, "div.j_readContent p")
    content = "\n".join([p.text for p in paragraphs])
    
    return title, content

def main():
    driver = setup_driver()
    os.makedirs(OUTPUT_FOLDER, exist_ok=True)

    chapter_links = get_chapter_links(driver, NOVEL_URL)

    if chapter_links:
        # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„ÙØµÙˆÙ„ Ù„Ù„Ø³Ø­Ø¨
        links_to_scrape = chapter_links[:CHAPTER_LIMIT] if CHAPTER_LIMIT else chapter_links
        print(f"\nğŸš€ Ø³ØªØ¨Ø¯Ø£ Ø¹Ù…Ù„ÙŠØ© Ø³Ø­Ø¨ {len(links_to_scrape)} ÙØµÙ„...\n")

        for i, link in enumerate(links_to_scrape):
            title, content = scrape_chapter(driver, link)
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ù…Ù† Ø§Ù„Ø£Ø­Ø±Ù ØºÙŠØ± Ø§Ù„ØµØ§Ù„Ø­Ø©
            safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '.')).rstrip()
            filename = f"{i+1:04d} - {safe_title}.txt"
            filepath = os.path.join(OUTPUT_FOLDER, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(f"Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {title}\n\n")
                f.write(content)
            
            print(f"   âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ÙØµÙ„ ÙÙŠ: {filepath}")

    driver.quit()
    print("\nğŸ‰ğŸ‰ğŸ‰ Ø§ÙƒØªÙ…Ù„Øª Ø¹Ù…Ù„ÙŠØ© Ø³Ø­Ø¨ Ø§Ù„ÙØµÙˆÙ„ Ø¨Ù†Ø¬Ø§Ø­! ğŸ‰ğŸ‰ğŸ‰")

if __name__ == "__main__":
    main()
